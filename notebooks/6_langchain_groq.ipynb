{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2943324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3acc893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c6f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cacf964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### What is GenAI?  \n",
      "**GenAI** (short for *Generative Artificial Intelligence*) refers to a class of AI systems that can **create** new content—text, images, audio, video, code, and even 3‑D models—rather than just analyze or classify existing data. Think of it as an AI “artist” or “writer” that learns from huge amounts of data and then produces something that *could* have been written or created by a human.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Core Idea\n",
      "\n",
      "| Traditional AI | GenAI |\n",
      "|-----------------|-------|\n",
      "| *Discriminative* models: learn to predict a label or answer (e.g., “Is this spam?”) | *Generative* models: learn to produce new samples that resemble the training data (e.g., “Write a poem about the ocean”) |\n",
      "| Works with fixed inputs → fixed outputs | Works with a prompt → free‑form output |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. How It Works (High‑Level)\n",
      "\n",
      "1. **Data Collection**  \n",
      "   - Massive datasets (text corpora, image collections, audio libraries, etc.) are assembled.  \n",
      "   - Example: GPT‑4 was trained on hundreds of billions of words from books, websites, and other text sources.\n",
      "\n",
      "2. **Model Architecture**  \n",
      "   - Most modern GenAI uses *transformers*, a neural‑network architecture that excels at capturing long‑range dependencies.  \n",
      "   - The model has *layers* of attention mechanisms that allow it to “focus” on relevant parts of the input when generating each token.\n",
      "\n",
      "3. **Training (Self‑Supervised)**  \n",
      "   - The model is trained to predict the next token (word, pixel, etc.) given all previous tokens.  \n",
      "   - Loss functions (e.g., cross‑entropy) measure how close the prediction is to the actual next token.  \n",
      "   - Through back‑propagation, the model adjusts millions/billions of weights to minimize this loss.\n",
      "\n",
      "4. **Inference (Generation)**  \n",
      "   - At run‑time, you give the model a *prompt* (e.g., a question or a starting sentence).  \n",
      "   - The model uses the learned weights to produce the next token, then iteratively continues until a stopping criterion is met (max length, special token, etc.).  \n",
      "   - Sampling strategies (greedy, beam search, nucleus sampling, temperature control) decide how deterministic or creative the output is.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Popular Generative Models\n",
      "\n",
      "| Domain | Example Model | Key Features |\n",
      "|--------|---------------|--------------|\n",
      "| Text | GPT‑4, Claude, Gemini | Large language model, few‑shot prompting, fine‑tuning |\n",
      "| Images | DALL‑E 2, Stable Diffusion, Midjourney | Text‑to‑image generation, diffusion processes |\n",
      "| Audio | Jukebox (OpenAI), MusicLM | Music generation from text prompts |\n",
      "| Video | VideoGPT, DALL‑E‑3 (video extension), Make‑A‑Video | Frame‑by‑frame synthesis, temporal coherence |\n",
      "| Code | Codex, GitHub Copilot | Suggests code snippets, auto‑completion |\n",
      "| 3‑D/AR | DreamBooth, GenSLAM | 3‑D object generation, scene understanding |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Why It Matters\n",
      "\n",
      "| Benefit | Example |\n",
      "|---------|---------|\n",
      "| **Productivity** | Auto‑generate emails, reports, or code snippets. |\n",
      "| **Creativity** | Artists use GenAI for concept art, music, or storytelling. |\n",
      "| **Accessibility** | Translate text, create captions, or generate content for the visually impaired. |\n",
      "| **Personalization** | Tailor content to user preferences in real time. |\n",
      "| **Innovation** | Rapid prototyping in design, simulation, and R&D. |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Key Concepts & Terminology\n",
      "\n",
      "- **Prompt** – The user’s input that guides the generation.  \n",
      "- **Token** – The smallest unit of text the model processes (often sub‑words).  \n",
      "- **Sampling Strategy** – Determines how the model selects the next token (e.g., temperature, top‑k, nucleus).  \n",
      "- **Fine‑Tuning** – Adapting a pre‑trained model to a specific domain or style.  \n",
      "- **Safety & Alignment** – Techniques to reduce harmful or biased outputs (e.g., RLHF, content filtering).  \n",
      "- **Inference Latency** – Time taken to produce output; critical for real‑time applications.  \n",
      "\n",
      "---\n",
      "\n",
      "## 6. Ethical & Societal Considerations\n",
      "\n",
      "| Issue | Impact | Mitigations |\n",
      "|-------|--------|-------------|\n",
      "| **Plagiarism & Authorship** | Generated content may replicate copyrighted text. | Copyright‑aware training, watermarking, licensing agreements. |\n",
      "| **Misinformation** | AI can produce realistic but false narratives. | Fact‑checking modules, source attribution. |\n",
      "| **Bias & Fairness** | Models inherit biases present in training data. | Diverse datasets, bias audits, fairness constraints. |\n",
      "| **Job Displacement** | Automation of creative tasks. | Upskilling, new roles in AI oversight, hybrid human‑AI workflows. |\n",
      "| **Privacy** | Training data may contain personal info. | Data scrubbing, differential privacy, federated learning. |\n",
      "\n",
      "---\n",
      "\n",
      "## 7. How to Get Started\n",
      "\n",
      "1. **Choose a Platform**  \n",
      "   - Cloud APIs (OpenAI, Anthropic, Google, Azure) for quick prototyping.  \n",
      "   - Open‑source frameworks (Hugging Face Transformers, Diffusers) for local deployment.\n",
      "\n",
      "2. **Define Your Use‑Case**  \n",
      "   - Content generation, code assistance, image editing, etc.\n",
      "\n",
      "3. **Select a Model & Prompt**  \n",
      "   - Start with a pre‑trained model; experiment with prompt engineering.  \n",
      "   - Example prompt for GPT‑4: “Write a short story about a robot learning to paint.”\n",
      "\n",
      "4. **Iterate & Evaluate**  \n",
      "   - Measure quality (BLEU, ROUGE, human judgment).  \n",
      "   - Fine‑tune if needed; consider RLHF or domain‑specific data.\n",
      "\n",
      "5. **Implement Safety Layers**  \n",
      "   - Content filters, user moderation, and monitoring.\n",
      "\n",
      "---\n",
      "\n",
      "## 8. Quick Reference Cheat Sheet\n",
      "\n",
      "| Task | Best‑Suited Model | Typical Prompt |\n",
      "|------|-------------------|----------------|\n",
      "| Text summarization | GPT‑4, LLaMA | “Summarize the following article in 3 bullet points.” |\n",
      "| Code generation | Codex | “Write a Python function that sorts a list of dictionaries by key ‘age’.” |\n",
      "| Image creation | Stable Diffusion | “A cyberpunk city at dusk, neon lights, rain.” |\n",
      "| Music composition | MusicLM | “Compose a 2‑minute ambient track for meditation.” |\n",
      "\n",
      "---\n",
      "\n",
      "### Bottom Line\n",
      "\n",
      "Generative AI is the frontier where machines can *create* instead of merely *recognize*. By learning patterns from vast datasets, these models can produce novel, high‑quality content across many modalities. While the technology unlocks unprecedented opportunities, it also demands careful attention to ethics, safety, and responsible deployment.  \n",
      "\n",
      "Feel free to ask if you want deeper dives into any specific area—whether it’s the math behind transformers, how to fine‑tune a model, or best practices for responsible use!\n"
     ]
    }
   ],
   "source": [
    "res = llm.invoke(\"Can you explain me GenAI?\")\n",
    "print(res.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
