{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008d50dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ba072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33eec7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\",streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b11d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Can you explain me GENAI?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bf3003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.stream(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2f7f63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object BaseChatModel.stream at 0x000002826263F2E0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f6f0198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## What is GENAI?\n",
      "\n",
      "**GENAI** is a shorthand for **Generative Artificial Intelligence**—the branch of AI that creates new content (text, images, audio, video, code, etc.) instead of just recognizing patterns or making predictions. Think of it as a “creative partner” that can write, design, compose, or even build things on its own, guided by the data it has learned from.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. Core Idea\n",
      "\n",
      "| Traditional AI | Generative AI |\n",
      "|----------------|---------------|\n",
      "| *Recognize* patterns → classify or predict | *Create* new data that resembles the training data |\n",
      "| Example: Spam filter, image classifier | Example: ChatGPT, DALL·E, Stable Diffusion |\n",
      "| Goal: Decision‑support | Goal: Content creation & augmentation |\n",
      "\n",
      "---\n",
      "\n",
      "### 2. How It Works (High‑Level)\n",
      "\n",
      "1. **Data Collection**  \n",
      "   - Large datasets (books, websites, photos, audio, code, etc.) are gathered.\n",
      "\n",
      "2. **Training a Model**  \n",
      "   - Neural networks (mostly *transformers* for text, *diffusion models* for images, *autoregressive models* for music) learn statistical patterns.\n",
      "   - The model learns a *probability distribution* over the data space.\n",
      "\n",
      "3. **Generation**  \n",
      "   - Given a prompt or seed, the model samples from this learned distribution to produce new content that “looks” like the training data but is not a copy.\n",
      "\n",
      "4. **Fine‑Tuning & Prompt Engineering**  \n",
      "   - Adjustments or additional training on specific tasks or styles to improve relevance and quality.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Popular Generative Models\n",
      "\n",
      "| Domain | Model | Key Feature |\n",
      "|--------|-------|-------------|\n",
      "| **Text** | GPT‑4, Claude, LLaMA | Large‑scale language generation, contextual understanding |\n",
      "| **Images** | DALL·E 3, Stable Diffusion, Midjourney | Text‑to‑image, style transfer, inpainting |\n",
      "| **Audio** | Jukebox, MusicLM | Music composition, voice cloning |\n",
      "| **Video** | Imagen Video, Make‑It‑Real | Frame‑by‑frame generation, upscaling |\n",
      "| **Code** | GitHub Copilot, AlphaCode | Autocomplete, code generation from natural language |\n",
      "\n",
      "---\n",
      "\n",
      "### 4. Use Cases\n",
      "\n",
      "| Industry | Example Applications |\n",
      "|----------|----------------------|\n",
      "| **Content Creation** | Blog writing, social media posts, marketing copy |\n",
      "| **Design & Art** | Concept art, product mockups, fashion sketches |\n",
      "| **Entertainment** | Story generation, game NPC dialogues, music tracks |\n",
      "| **Education** | Personalized tutoring, interactive textbooks |\n",
      "| **Healthcare** | Medical report drafting, drug discovery (generating molecular structures) |\n",
      "| **Business** | Data‑driven reports, automated customer support, code scaffolding |\n",
      "| **Accessibility** | Text-to-speech, image descriptions, language translation |\n",
      "\n",
      "---\n",
      "\n",
      "### 5. Key Concepts & Terms\n",
      "\n",
      "| Term | What It Means |\n",
      "|------|---------------|\n",
      "| **Transformer** | Neural architecture that excels at sequence modeling (text, audio). |\n",
      "| **Diffusion Model** | Generates images by iteratively “denoising” a random noise input. |\n",
      "| **Prompt Engineering** | Crafting inputs (text, images) to steer the model toward desired outputs. |\n",
      "| **Fine‑Tuning** | Training a pre‑trained model further on a specific dataset to adapt its style or knowledge. |\n",
      "| **Token** | Smallest unit of input (word, sub‑word, or character) used by language models. |\n",
      "| **Zero‑Shot** | Model performs a task without task‑specific training. |\n",
      "| **Few‑Shot** | Model is given a handful of examples to guide it. |\n",
      "\n",
      "---\n",
      "\n",
      "### 6. Strengths\n",
      "\n",
      "- **Creativity & Speed**: Generates ideas and drafts in seconds.\n",
      "- **Scalability**: Handles large volumes of content with minimal human effort.\n",
      "- **Personalization**: Tailors outputs to user preferences or brand voice.\n",
      "- **Cross‑Modal**: Combines text, image, audio, and code generation in a single pipeline.\n",
      "\n",
      "---\n",
      "\n",
      "### 7. Limitations & Risks\n",
      "\n",
      "| Area | Challenge |\n",
      "|------|-----------|\n",
      "| **Accuracy** | May produce plausible‑but‑false facts (hallucinations). |\n",
      "| **Bias** | Reflects biases present in training data. |\n",
      "| **Copyright** | Generates content that can infringe on existing works. |\n",
      "| **Ethics** | Potential misuse for misinformation, deepfakes, or harmful content. |\n",
      "| **Energy & Cost** | Training large models consumes significant compute and electricity. |\n",
      "\n",
      "---\n",
      "\n",
      "### 8. Ethical & Regulatory Landscape\n",
      "\n",
      "- **Transparency**: Models should disclose that content is AI‑generated.\n",
      "- **Consent & Attribution**: Respect creators’ rights and give proper credit.\n",
      "- **Bias Audits**: Regularly test for and mitigate discriminatory outputs.\n",
      "- **Governance**: Many countries are drafting AI‑specific regulations (e.g., EU’s AI Act).\n",
      "\n",
      "---\n",
      "\n",
      "### 9. Future Directions\n",
      "\n",
      "- **Multimodal Models**: Seamless integration of text, image, audio, and video generation.\n",
      "- **Smaller, Efficient Models**: Edge deployment for smartphones and IoT devices.\n",
      "- **Explainability**: Better tools to interpret why a model produced a particular output.\n",
      "- **Human‑in‑the‑Loop Systems**: Combining AI creativity with human oversight for higher quality and safety.\n",
      "\n",
      "---\n",
      "\n",
      "## TL;DR\n",
      "\n",
      "- **GENAI** = Generative AI = AI that *creates* new content.\n",
      "- Powered by large neural networks (transformers, diffusion models, etc.).\n",
      "- Used across industries: writing, design, music, coding, healthcare, and more.\n",
      "- Excels in speed and creativity but must be managed carefully to avoid bias, hallucinations, and misuse.\n",
      "\n",
      "Feel free to ask if you'd like deeper dives into any specific model, industry application, or technical detail!"
     ]
    }
   ],
   "source": [
    "response = llm.stream(question)\n",
    "for chunk in response:\n",
    "    print(chunk.content, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
